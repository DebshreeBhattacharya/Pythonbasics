{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Different formats for data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Array: Numpy or Panda Dataframe\n",
    "* Array: Images\n",
    "* Array: Time changing/ Time Dependednt Signals\n",
    "* Array: Text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Music/ Audio Signals"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Machine learning for audio signals? YouTube, Spotify, Prime Music.........! <br>\n",
    "Songs are analyzed based on their digital signatures for some factors, including tempo, acoustics, energy, danceability etc. <br>\n",
    "ML used to find these patterns in any given music signal and then these obtained patterns are used for further music analysis, such as genre classification or music recognition.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Audio processing in Python"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sound is represented in the form of an audio signal having parameters such as frequency, bandwidth, decibel etc. <br>\n",
    "A typical audio signal can be expressed as a function of Amplitude and Time.\n",
    "<img src=\"sound.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Any given signal can be represnted in both time domain and frequency domain. <br>\n",
    "The audio signal is a three-dimensional signal in which three axes represent time, amplitude and frequency.\n",
    "<img src=\"sound_rep.jpeg\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Librosa\n",
    "It is a Python module to analyze audio signals in general but geared more towards music.<br>\n",
    "Documentation for installation and reference: https://librosa.org/doc/latest/index.html <br>\n",
    "##### Installation\n",
    "pip install librosa <br>\n",
    "or <br>\n",
    "conda install -c conda-forge librosa"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### IPython.display.Audio\n",
    "IPython.display.Audio lets you play audio directly in a jupyter notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# !conda install -c conda-forge librosa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import librosa\n",
    "audio_path = 'triumphant_bong_no_focus.wav'\n",
    "x , sr = librosa.load(audio_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(type(x), type(sr))\n",
    "print(x.shape, sr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What is sampling rate? And how to change it?\n",
    "The sample rate is the number of samples of audio carried per second, measured in Hz or kHz."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y, sry = librosa.load(audio_path, sr=44100)\n",
    "print(sry)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import IPython.display as ipd\n",
    "ipd.Audio(audio_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualising Audio\n",
    "Plot the audio array using librosa.display.waveplot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import librosa.display\n",
    "plt.figure(figsize=(14, 5))\n",
    "librosa.display.waveshow(x, sr=sr)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**librosa.display** is used to display the audio files in different formats such as wave plot, spectrogram, or colormap.<br> **Waveplots** let us know the loudness of the audio at a given time. <br> **Spectogram** shows different frequencies playing at a particular time along with it’s amplitude."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Spectrogram\n",
    "<br>\n",
    "A spectrogram is a visual representation of the spectrum of frequencies of sound or other signals as they vary with time. It’s a representation of frequencies changing with respect to time for given music signals."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x.shape, X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = librosa.stft(x)\n",
    "Xdb = librosa.amplitude_to_db(abs(X))\n",
    "plt.figure(figsize=(14, 5))\n",
    "librosa.display.specshow(Xdb, sr=sr, x_axis='time', y_axis='hz')\n",
    "plt.colorbar()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The vertical axis shows frequencies (from 0 to 10kHz), and the horizontal axis shows the time of the clip. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "STFT: Amplitude of given frequency at a given time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "librosa.display.specshow(Xdb, sr=sr, x_axis='time', y_axis='log')\n",
    "plt.colorbar()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create your own sound"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "sr = 22050 # sample rate\n",
    "T = 5.0    # seconds\n",
    "t = np.linspace(0, T, int(T*sr), endpoint=False) # time variable\n",
    "r = np.random.random(int(T*sr))\n",
    "c = np.zeros(int(T*sr)) + 10\n",
    "x_own = c + r #0.5*np.sin(2*np.pi*220*t) + 0.5*np.sin(2*np.pi*101*r) # pure sine wave at 220 Hz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ipd.Audio(x_own, rate=sr) # load a NumPy arrayb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(T*sr)\n",
    "plt.figure(figsize=(14, 5))\n",
    "librosa.display.waveshow(x_own, sr=sr) #[100:500]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Extraction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Every audio signal consists of many features. <br>\n",
    "Extract the characteristics that are relevant to the problem we are trying to solve! <br>\n",
    "The process of extracting features to use them for analysis is called **feature extraction**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Zero Crossing Rate\n",
    "The zero crossing rate is the rate of sign-changes along a signal, i.e., the rate at which the signal changes from positive to negative or back. <br>\n",
    "Used in both speech recognition and music information retrieval. <br>\n",
    "It usually has higher values for highly percussive sounds like those in metal and rock."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualise the audio\n",
    "# How to visualise a particular section of this audio?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(14, 5))\n",
    "librosa.display.waveshow(x[6800:7000], sr=sr)\n",
    "print(len(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#zero_crossings = librosa.zero_crossings(x, pad=False)\n",
    "zero_crossings = librosa.zero_crossings(x[6800:7000], pad=False)\n",
    "print(len(zero_crossings))\n",
    "print(sum(zero_crossings))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Spectral Centroid"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It indicates where the ”centre of mass” for a sound is located and is calculated as the weighted mean of the frequencies present in the sound. If the frequencies in music are same throughout then spectral centroid would be around a centre and if there are high frequencies at the end of sound then the centroid would be towards its end."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spectral_centroids = librosa.feature.spectral_centroid(x, sr=sr)[0]\n",
    "frames = range(len(spectral_centroids))\n",
    "t = librosa.frames_to_time(frames)\n",
    "print(len(frames))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ".spectral_centroid is used to calculate the spectral centroid for each frame. So it’ll return an array with columns equal to a number of frames present.<br>\n",
    ".frames_to_time converts frame to time. time[i] == frame[i]."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn\n",
    "def normalize(x, axis=0):\n",
    "    return sklearn.preprocessing.minmax_scale(x, axis=axis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "librosa.display.waveshow(x, sr=sr, alpha=0.4)\n",
    "plt.plot(t, normalize(spectral_centroids), color='r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "librosa.display.waveshow(x, sr=sr, alpha=0.4)\n",
    "plt.plot(t, normalize(spectral_centroids), color='r')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Spectral Rolloff\n",
    "It is a measure of the shape of the signal. It represents the frequency below which a specified percentage of the total spectral energy, e.g. 85%, lies. <br>\n",
    "librosa.feature.spectral_rolloff computes the rolloff frequency for each frame in a signal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "spectral_rolloff = librosa.feature.spectral_rolloff(x+0.01, sr=sr)[0]\n",
    "librosa.display.waveshow(x, sr=sr, alpha=0.4)\n",
    "print(len(spectral_rolloff))\n",
    "plt.plot(t, normalize(spectral_rolloff), color='r')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mel Scale"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A mel is a number that corresponds to a pitch, similar to how a frequency describes a pitch. <br>\n",
    "Humans do not perceive frequencies on a linear scale. We are better at detecting differences in lower frequencies than higher frequencies.<br>\n",
    "\n",
    "500-1000Hz: Yes <br>\n",
    "10,000-10,500Hz: No\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Mel Scale:** A unit of pitch such that equal distances in pitch sounded equally distant to the listener."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_mels = 128\n",
    "mel = librosa.filters.mel(sr=sr, n_fft=2048, n_mels=n_mels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 4))\n",
    "hop_length = 512\n",
    "n_fft=2048\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "librosa.display.specshow(mel, sr=sr, hop_length=hop_length, x_axis='linear')\n",
    "plt.ylabel('Mel filter')\n",
    "plt.colorbar()\n",
    "plt.title('1. Our filter bank for converting from Hz to mels.')\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "mel_10 = librosa.filters.mel(sr=sr, n_fft=n_fft, n_mels=10)\n",
    "librosa.display.specshow(mel_10, sr=sr, hop_length=hop_length, x_axis='linear')\n",
    "plt.ylabel('Mel filter')\n",
    "plt.colorbar()\n",
    "plt.title('2. Easier to see what is happening with only 10 mels.')\n",
    "\n",
    "\n",
    "#plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mel Spectrogram"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A Spectrogram with the Mel Scale as its y axis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spec = librosa.feature.melspectrogram(y=x, sr=sr)\n",
    "import librosa.display\n",
    "librosa.display.specshow(spec,y_axis='mel', x_axis='s', sr=sr)\n",
    "plt.colorbar()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Log Mel Spectrogramm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "db_spec = librosa.power_to_db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "db_spec = librosa.power_to_db(spec, ref=np.max,)\n",
    "librosa.display.specshow(db_spec,y_axis='mel', x_axis='s', sr=sr)\n",
    "plt.colorbar()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mel-Frequency Cepstral Coefficients (MFCC)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Mel frequency cepstral coefficients (MFCCs) of a signal are a small set of features (usually about 10–20) which concisely describe the overall shape of a spectral envelope. <br>\n",
    "<br>\n",
    "The mel-frequency cepstrum (MFC) is a representation of the short-term power spectrum of a sound, based on a linear cosine transform of a log power spectrum on a nonlinear mel scale of frequency."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mfccs = librosa.feature.mfcc(x, sr=sr)\n",
    "print(mfccs.shape)\n",
    "\n",
    "#Displaying  the MFCCs:\n",
    "librosa.display.specshow(mfccs, sr=sr, x_axis='time')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn\n",
    "mfccs = sklearn.preprocessing.scale(mfccs, axis=1)\n",
    "print(mfccs.mean(axis=1))\n",
    "print(mfccs.var(axis=1))\n",
    "librosa.display.specshow(mfccs, sr=sr, x_axis='time')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Chroma Frequency"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Chroma features are an interesting and powerful representation for music audio in which the entire spectrum is projected onto 12 bins representing the 12 distinct semitones (or chroma) of the musical octave."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hop_length = 512\n",
    "chromagram = librosa.feature.chroma_stft(x, sr=sr, hop_length=hop_length)\n",
    "plt.figure(figsize=(15, 5))\n",
    "librosa.display.specshow(chromagram, x_axis='time', y_axis='chroma', hop_length=hop_length, cmap='coolwarm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
